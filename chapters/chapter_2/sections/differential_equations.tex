\chapter{Background}

In this chapter, I describe the necessary background for the research presented in this thesis, covering four key topics: differential equations, Bayesian statistics, pharmacokinetics, and dynamic treatment regimes.  Much of this thesis concerns drug concentrations and decisions therein which optimize the concentrations subject to some criteria.  Pharmacokinetics concerns itself with the absorption, distribution, metabolization, and elimination of a drug from the body, making it an important framework to use when reasoning about drug concentrations. The models used in pharmacokinetics are written in terms of differential equations, hence a working knowledge of differential equations and their properties is needed in order to reason about the pharmacokinetic models.  Bayesian statistics is used to combine prior information of pharmacokinetic phenomena with data in order to perform inference on the pharmacokinetic model parameters, as well as to simulate new data and perform model validation.  Dynamic treatment regimes are a formalization of sequential decision making. Since personalized medicine involves sequential decisions (on say the next dose size to prescribe to a patient, as an example), the dynamic treatment regime framework will be relevant to formally reason about decision making.

The focus of the first section is differential equations, specifically first order separable equations and the Laplace Transform.  I briefly discuss conditions under which a differential equation has a unique solution, as well as techniques for qualitative analysis of a system's dynamics under families of equivalent parameterizations.  Then, I discuss Bayesian statistics, touching on model design, model checking, and model fitting.  In the next section I discuss population pharmacokinetic models, touching on their derivation through differential equations as well as extensions to include multiple doses.  I conclude this chapter with a treatment of dynamic treatment regimes and estimation of an optimal policy through Q learning.

\section{Differential Equations}\label{sec:ODE}

\subsection{Initial Value Problems, Existence, and Uniqueness}

A differential equation relates an unknown function $y(t)$ to its derivative $y'(t)$ through a known function $f(t, y(t), \theta)$ \cite{morris1963ordinary}. Here, the function $f$ may depend on parameters, $\theta$ which can be known exactly or require estimation from data. For economy of thought, dependence of $f$ on $\theta$ is implied though not always explicitly stated. A differential equation is called \textit{ordinary} (referred to as an \textit{ODE}) if $y$ is a function of a single scalar variable $t$, which for the purposes of this thesis can be considered to be time. An ODE together with an \textit{initial condition} -- a value of $y$ at some point $t_0$ in its domain --  is referred to as an \textit{initial value problem} (or sometimes an \textit{IVP}), 

\begin{equation}\label{IVP}
	\dfrac{dy(t)}{dt} = f(t, y(t), \theta) \quad y(t_0) = y_0
\end{equation}

\noindent Here, $y(t)$ could represent the concentration of a drug in the blood as a function of time, $t_0$ could be some time after the drug was ingested, and $y_0$ could be the concentration at $t_0$.  If the function $f$ can be written as $f(t, y(t)) = Q(t) - I(t) y(t)$, then we call the ODE a \textit{first order linear ordinary differential equation}.  Often, the differential equation is written with all terms involving $y(t)$ on one side, such as $dy/dt + I(t) y(t) = Q(t)$, in which case $Q(t)$ is referred to as the \textit{forcing function}.  First order linear equations are of particular interest, as they are easily solved analytically and are sufficient to model pharmacokinetic under certain assumptions of how the body acts on the drug.

%\todo[inline]{why is linear relevant here? - foreshadow that they will be sufficient for compartment models?}

Not every IVP which can be written down has a solution, but there do exist general criteria for existence and uniqueness to a solution for \cref{IVP}.  The only requirements are that a) $f$ be continuous in $t$, and b) $f$ be Lipschitz continuous in $y$.  Under these conditions, Picard–Lindelöf theorem \cite{morris1963ordinary} guarantees a unique solution exists.

\begin{theorem}[\emph{Picard–Lindelöf Theorem}]
	Let $D \subseteq \mathbb{R} \times \mathbb{R}^n$ be a closed rectangle with $(t_0, y_0) \in D$, and let $f : D \to \mathbb{R}^n$ be a function that is continuous in $t$ and Lipschitz continuous in $y$.  Then, there exists some $\epsilon>0$ such that \cref{IVP} has a unique solution $y(t)$ in an interval centred at $t_0$ with radius $\epsilon$.
\end{theorem}

\noindent This thesis is mainly concerned with functions $f$ which are continuous in $y$.  If a function is continuous in a variable, then it is also Lipschitz continuous in that variable.  Hence, all IVPs for which we concern ourselves with have a unique solution. 


\subsection{Solutions to First Order Linear Equations}

So long as the function $f(t, y(t)) = Q(t) - I(t) y(t)$ satisfies the conditions for the Picard–Lindelöf theorem, then a solution exists and it is unique.  Assuming $Q(t)$ and $I(t)$ are written in terms of analytic functions, then the solution to \cref{IVP} can be written out analytically.  Let $P(t) = \exp(\int I(t) \, dt)$ be an \textit{integrating factor}.  Multiplying both sides of the ODE by $P(t)$ yields

\begin{align}
	\dfrac{dy}{dt} + I(t)y(t) &= Q(t) \\
	P(t)\dfrac{dy}{dt} + P(t)I(t)y(t) &= P(t)Q(t) 
\end{align}

\noindent  The form of $P(t)$ implies $P'(t) = P(t)I(t)$, and so the left hand side of the differential equation looks as if it is the result of the product rule

\begin{align}
 \dfrac{d}{dt} \Big( P(t)y(t) \Big) &= P(t)\dfrac{dy}{dt} + P(t)I(t)y(t) \\
														  &= P(t) Q(t)
\end{align}

\noindent Integrating and division by $P(t)$ (which is possible since $P(t)>0$ by construction) yields the solution to the differential equation

\begin{equation}
	y(t) = \dfrac{\int Q(t) P(t)\, dt}{P(t)},
\end{equation}

\noindent wherein the constant of integration from the numerator is determined by using the initial condition. The general takeaway is that so long as $f$ satisfies the conditions for the Picard–Lindelöf theorem, and $Q(t)$ and $I(t)$ are not sufficiently complicated so as to prevent integration, then the solution to \cref{IVP} can be written down exactly.


\subsection{Non-dimensionalization}

Differential equations representing physical systems can often have several parameters, and the qualitative behaviour for the solution can be similar across many different families of parameterizations. A technique used by applied mathematicians to study the qualitative behaviour of a differential equation is known as \textit{non-dimensionalization} \cite[p.~25]{holmes2009introduction}.  The technique involves rescaling the solution $y(t)$ (the units of which depend on what is being modelled) and the time variable $t$ (which could be measured in seconds, hours, minutes, etc.) to be unitless. Let $a \neq 0$ be measured in the same units as $t$ and let $b \neq 0$ be measured in the same units as $y$.  Then, we can define non-dimensional variables $\tau$ and $x$ so that $t = a \tau $ and $y = b x$.  The non-dimensionalization of the differential equation $dy/dt = f(t, y(t))$  in terms of $\tau$ and $x$ is obtained by applications of differentiation rules

\begin{align}
	\dfrac{d }{dt} \Big( y(t) \Big) &=  	\dfrac{d }{dt} \Big( b x(\tau) \Big)\\
													&= b \dfrac{dx(\tau) }{d\tau} \dfrac{d \tau}{dt}\\
													&= \dfrac{b}{a} \dfrac{dx(\tau)}{d\tau}
\end{align}


\noindent which yields $dx / d \tau = a/b f(a\tau, bx(\tau))$.  The approach is similar to normalization in statistics (i.e.\ subtracting the mean and dividing by the standard deviation).  The re-scaling allows one to examine families equivalently parameterized differential equations, giving insight into the characteristic dynamics of the system. Non-dimensionalizing a differential equation will important when defining prior distributions over parameters in Bayesian inference.

\subsection{The Laplace Transform and Discontinuous Forcing Functions}

Under the conditions that a function $f$ is piecewise continuous on an interval $0 \leq t \leq A$ for any positive $A$, and that $\vert f(t) \vert \leq K \exp(at)$ when $M \leq t$ for real constants $0< K, a, M $, then the integral

$$ \int_0^\infty f(t) e^{-st} \, dt  $$ 

\noindent exists and is called \textit{The Laplace Transform}, denoted $\mathcal{L}\left\{f\right\}(s)$ \cite[p.~317]{boyce2021elementary}.  


\noindent The Laplace Transform can be used to turn a first order linear differential equation into an algebraic equation due to the property that  $\mathcal{L}\left\{f'\right\}(s) = s\mathcal{L}\left\{f\right\}(s) - f(0) $, which can be demonstrated by applying integration by parts. The algebraic equation can then be solved and inverted from $s$ space to $t$ space.  The Laplace Transform can be used to solve differential equations with discontinuous forcing functions.  These differential equations take the form 

\begin{equation}
	\dfrac{dy}{dt} + I(t)y(t) = Q_1(t) + H(t)Q_2(t) \>.
\end{equation}

\noindent Here, $H(t)$ is a Heaviside step function

\begin{equation}
	H(t) = \begin{cases}  1 & t>0 \\ 0 & \mbox{else} \end{cases}
\end{equation}

\noindent  When $t<0$,  $Q_2(t)$ is essentially ``turned off'' and its effect on the dynamics of $y$ is 0.  When $t>0$, the effect is then ``turned on''. As an example, we consider a differential equation which will be of use in the remainder of this thesis

\begin{equation}
	\dfrac{dy}{dt} + \alpha y(t) = \exp(-t)  + H(t - t_1) \exp(-(t - t_1)) \quad y(0) = 0 \>.
\end{equation}

\noindent Here, the dynamics undergo a force of $\exp(-(t-t_1))$ when $0<t_1 \leq t$.  The Laplace Transform can be used on both sides (leveraging tables of Laplace Transforms for common functions \cite{boyce2021elementary}) of the differential equation to yield

$$ s\mathcal{L}\left\{y\right\}(s) - y(0) + \alpha \mathcal{L}\left\{y\right\}(s) = \dfrac{1 + \exp(-st_1)}{1+s} \>.  $$

\noindent The equation is now algebraic in terms of $\mathcal{L}\left\{y\right\}(s)$.  Solving for $\mathcal{L}\left\{y\right\}(s)$ yields

\begin{equation}
	\mathcal{L}\left\{y\right\}(s) =  \dfrac{1 + \exp(-st_1)}{1+s} \dfrac{1}{s+\alpha} \>,
\end{equation}

\noindent and applying the inverse Laplace Transform yields

\begin{equation}
	y(t) = \dfrac{\Big(\exp(-t) - \exp(-\alpha t)\Big) + H(t-t_1)\Big(\exp(-(t-t_1)) - \exp(-\alpha(t-t_1))\Big)}{\alpha-1}
\end{equation}

\noindent  Because the two forcing functions in the differential equation were identical (one was just shifted $t_1$ units to the right) the solution to the differential equation is comprised of the same two functions, one of which is shifted $t_1$ units to the right.  The Laplace Transform will be of particular use when deriving solutions to differential equations which describe mass transit of a drug through the blood.  In these applications, multiple doses are taken through time and can be represented as discontinuous forcing functions using Heaviside functions.  When a patient takes a dose of a drug, the effect of that dose on the system dynamics is ``turned on'' at the time of ingestion. Additionally, because the Laplace Transform is a linear operator, we can consider arbitrarily many discontinuous forcing functions. Pharmacokinetic models where patients take multiple doses of a drug can be expressed as first order linear differential equations with discontinuous forcing functions, and so the Laplace Transform will be an important technique for solving these differential equations exactly.