---
title: "Bayesian Pharmacokinetic Models for Inference and Optimal Sequential Decision Making"
subtitle: "with Applications in Personalized Medicine" 
fontsize: 10pt
author: "Demetri Pananos M.Math" 
date: "October 19 2022"
bibliography: "thesis_bib.bib"
csl: academic-medicine.csl
output:
  beamer_presentation:
    slide_level: 3
    keep_tex: false
institute: Department of Epidemiology and Biostatistics
header-includes: 
  - \usepackage{subfig}
  - \usepackage{graphicx}
  - \usepackage{booktabs}
  - \usepackage{setspace}
  - \usepackage{xcolor}
  - \usepackage{multicol}
  - \usepackage{tikz}
  - \usepackage{bm}
  - \definecolor{uwo-purple}{HTML}{4F2683}
  - \definecolor{uwo-gray}{HTML}{807F83}
  - \usecolortheme[named=uwo-purple]{structure}
  - \setbeamertemplate{headline}{\hfill\includegraphics[width=2.5cm]{Figures/UWO_Horizontal_Full.png}\hspace{0.2cm}\vspace{-.8cm}}
  # set options for blocks 
  - \setbeamertemplate{blocks}[rounded]
  - \setbeamercolor{block title alerted}{fg=white, bg=uwo-purple} 
  # cahnge alert block colours 
  - \setbeamercolor{block body alerted}{bg=uwo-gray!25}
 # - \setbeamertemplate{footline}{\insertframenumber} # gets n/N 
  - \usepackage{threeparttablex}
  - \makeatletter
  - \setbeamertemplate{footline} { \tikz[overlay]{\node at(12,.25){\thepage};} }
  - \makeatother
  
# to get logo bottom right corner; works with Rochester theme
  # - \logo{\includegraphics[width=.1\textwidth]{./Figures/uwo-purple.png}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


### Motivation

* Different people react differently to the same drug. 

* Obstacle for optimal treatment:

  * Heightened response ($\to$ toxicity)
  * Lowered response ($\to$ inefficacy)
  
* Personalized medicine is a response to this problem.

### Personalized Medicine

*Personalized Medicine (PM)*: Application of genomic, demographic, and lifestyle factors as predictors of disease risk and individualization of drug therapy [@morse2015personalized].

Morse and Kim identify 4 goals of PM:

  1) Which drugs have excess variation?
  2) **Which factors drive variation?**
  3) **Personalize dose**
  4) Prevent adverse events

### Excess Variation Motivates Fine Tuning

* *Pharmacokinetics* (PK): Time course of drug concentrations in the body. 
  * Understand variation in concentration since drug concentration $\leftrightarrow$ drug exposure.
* Many PK studies provide dose adjustment criteria
* Still excess variation in response [@sukumar2019apixaban].  
* "Fine tune" to population at hand.

### How to "Fine Tune"

* Bayesian statistics
* Formalize sequential decision making with Dynamic Treatment Regimes (DTRs)
* Decisions in PM are based on concentrations (PK).  Synergy between PK modelling and DTRs.

### This Thesis

* Methods for creating Bayesian PK models for:
  * Inference on covariate effects on concentrations, and
  * Use in optimal sequential decision making on dose size.
  
Hence, this thesis is most closely aligned with goals \textcolor{uwo-purple}{(2) and (3)} of personalized medicine.

### Objectives & Contributions

* Compare/contrast existing approaches to fitting Bayesian models
  * Simulation study on decision quality.
* Framework for "is the juice worth the squeeze".
  * Simulation-based evaluation of personalization based on PK combined with DTRs.
* Demonstrate how PM researchers in academic centers can use all data available to them.
  * Demonstration how to combine different types of data with comments on how to maintain exchangeability.

## Paper 1: Comparisons Between HMC and MAP for a Bayesian Model for Apixiban Induction Dose and Dose Personalization

### Background

* Hamiltonian Monte Carlo (HMC) considered gold standard.
* Prior to that, Maximum A Posteriori (MAP) a popular method.
* Recently, theoretical arguments *against* using in some models.
* Question:
  * Are decisions in PM greatly affected by choice of inference method?
  * Answer: Predictions of concentration are similar, but uncertainty is different.  This affects decision quality.
  
### Motivating Theory

* Intuition for MAP starts in low dimensions
* Theory: "As dimensionality $\uparrow$, MAP is poorer approximation".
* For some PK models, number parameters $\propto 3 \times  \text{Number of subjects}$.

### Experiments

* Need a ground truth that looks similar to real data.
* Fit a model using HMC to real data and use posterior predictive to generate 100 new simulated patients.

$$ \overbrace{P(\tilde{y} \vert y)}^{\text{Posterior Pred.}} = \int_\theta \underbrace{P(\tilde{y} \vert \theta)}_{\text{Likelihood}} \overbrace{P(\theta \vert y)}^{\text{Posterior}} \, d \theta $$

* Refit the model on this simulated data, this time with MAP and HMC. 
* Compare decision quality based on two criteria:
  * Pick a dose so the maximum concentration is not too large (toxicity)
  * Pick a dose so the trough concentration is not too small (inefficacy)


### The (Real) Data

![](../figures/table1.png)

### The Model

* 1 Compartment PK model with first order elimination and absorption.
* Prior distributions derived from a 2019 review on apixaban pharmacokinetics.
* Each patient gets their own parameters through a random effect

$$ y_{j}(t_i) \sim \operatorname{Lognormal}(C_j(t_i), \sigma^2_y) $$
$$C_j(t)= \begin{cases}\frac{F \cdot D}{Cl_{j}} \frac{k_{e, j}\cdot k_{a, j}}{k_{e,j}-k_{a, j}}\left(e^{-k_{a, j}(t-\delta_j)}-e^{-k_{e, j}(t-\delta_j)}\right) & \delta \leq t \\ 0 & \text { else }\end{cases}$$
$$ \log(Cl_j) \sim \mathcal{N}(\mu_{Cl}, \sigma^2_{Cl}) $$$$ \log(t_{\max, j}) \sim \mathcal{N}(\mu_{t_{\max}}, \sigma^2_{t_{\max}}) $$
$$ \operatorname{logit}(\alpha_j) \sim \mathcal{N}(\mu_{\alpha}, \sigma^2_\alpha) $$
$$ \delta_j \sim \operatorname{Beta}(\phi \kappa \>, (1-\phi) \kappa) $$


* Prior distributions on $\mu$, $\sigma^2$, $\phi$, and $\kappa$.

### The Model

* $C(t)$ written in terms of $k_a, k_e$ but model written in terms of $t_{\max}, \alpha$.
* Two equations, two unknowns.

$$ \alpha = \dfrac{k_e}{k_a} \implies k_e = \alpha k_a $$

$$ t_{\max} = \dfrac{\ln(k_e) - \ln(k_a)}{k_e - k_a} \implies k_a = \dfrac{1}{t_{\max}} \dfrac{\ln(\alpha)}{\alpha-1}  $$

### The Model

* Consider $\theta_j = [Cl_j \>, t_{\max, j} \>, \alpha_j]^T$, $\sigma = [\sigma^2_{Cl}, \sigma^2_{t_{\max}}, \sigma^2_\alpha]^T$, and $\mu = [\mu_{Cl} \>, \mu_{t_{\max}} \>, \mu_\alpha]^T$.

<center>

![](../figures/model1.jpg){height=80%}

</center>

### Modelling Results 

![[Left] Draws from the prior distribution.  [Center] Two patients from our dataset. [Right] Posterior fits for the latent concentration.](../figures/fig3.png)


### Checking Decision Quality

* Prediction Error
* Decisions under uncertainty
  * Pick a time, $T$ (e.g. $t_{\max}$)
  * Pick a threshold, $c$
  * Pick a desired risk level, $R$.
  * Select a dose so that $P\Big(C(T) > c\Big) = R$

### Checking Decision Quality

* Approximately $R\times 100$ patients should exceed the threshold.
* Check the calibration of dosing decisions using models fit by MAP and HMC.

### Prediction Error Very Similar

* Prediction error is very similar, no reason to prefer one over the other.

```{r, echo=F, message=F, warning=F}
library(tidyverse)
library(kableExtra)

tribble(
  ~"Loss", ~'HMC', ~"MAP",
  "MSE (Sd)", "6.67 (15.93)", "8.57 (19.93)",
  "MAE (Sd)", "1.71 (1.94)", "1.97 (2.17)",
  "MAPE (Sd)",  "0.04 (0.03)", "0.05 (0.03)"
) %>% 
  kbl(format = 'latex') %>% 
  kable_styling(bootstrap_options = 'striped')
```

### Calibration is Very Different

* HMC very well calibrated, MAP not so much.
* Remember, same model and same priors. Different decisions.
* Why is this happening?

![Calibration on decisions. [Left] Calibration for decision on max concentration.  [Right] Calibration on trough concentration.](../figures/fig8.png){width=80%}

### Uncertainty is Larger in MAP Model

* MAP results in excess uncertainty as compared to HMC.
* Because decisions integrate over uncertainty, differences in uncertainty $\to$ differences in decisions.

![19 of the 100 simulated patients who demonstrate excess variation.](../figures/intervals.png){width=95%}

### Discussion

* MAP leads to different decisions than HMC.
  * Affect on decisions depends on the loss.
* MAP is fast and familiar to MLE, but it is not interchangeable with HMC for these types of models.
* Recommend that if you are to use MAP, invest the time to compare against HMC.

## Paper 2: Developing and Evaulating Pharmacokinetics-Driven Dynamic Personalized Medicine: A Framework and Case Study

### Introduction

* Many approaches to personalizing doses regress stable dose onto pre-dose covariates (**static personalization**).

* Has reduced -- but not eliminated -- the need for "trial-and-error" adjustments to the dose.

* Further opportunity to personalize the titration process (**dynamic personalization**).

### Introduction

* Dynamic personalization imposes additional burden on patient.

* "Is the juice worth the squeeze?"
  * Do the benefits outweigh burden?
  

### Why Is This Important?

* Circumstances for cost effectiveness of PM are unclear [@looff2016economic],[@shabaruddin2015economic].
* Additional variability in QALY for some modes of PM [@kasztura2019cost]. Question if burden is worth payoff persists.
* Need for PM to focus on constraints and utilities of patients [@rogowski2015concepts],[@di2017personalized].    
* Incorporating patient preferences $\to$ sustained adherence [@elliott2008understanding].


### Contribution

* Framework for evaluation of various static and dynamic modes of personalization.

* Can contribute evidence towards decisions on if a certain mode should be implemented

### Related Work

* Other studies which apply Q-learning.
* Rich et. al [@rich2014simulating] develop a SMART trial for optimal dose selection using pharmacokinetic data.
* Main differences:
  * Other studies often *estimate* the value function. 
  * Our value function based on PK model. 
  * Question now is "Is the value function based on PK the function we really want?" 
  
  
### Framework Outline

1. Have a model of PK for your drug
2. Simulate new patients from your model
3. Select doses on these simulated subjects using selected modes
4. Evaluate on their ability to achieve desired result


We provide an example using apixaban.

###  Step 1. Model and Step 2.  Simulate

* Similar to before, but adjust for covariates and allow for multiple doses

* Similar to last model, but now adjust for patient covariates and allow for multiple doses.

$$\tilde{C}(t) = \sum_{j=0} ^ {20} C(t-12j)H(t-12j)$$

$$C_j(t)= \begin{cases}\frac{F \cdot D_j}{Cl_{j}} \frac{k_{e, j}\cdot k_{a, j}}{k_{e,j}-k_{a, j}}\left(e^{-k_{a, j}(t-\delta_j)}-e^{-k_{e, j}(t-\delta_j)}\right) & \delta \leq t \\ 0 & \text { else }\end{cases}$$


$$ \log(Cl_j) \sim \mathcal{N}\Big(\mu_{Cl,j} + \mathbf{x}^{Cl}_j \beta_{Cl}\>, \sigma^2_{Cl}\Big)$$
$$ \log(t_{\max, j}) \sim \mathcal{N}\Big(\mu_{t_{\max, j}} + \mathbf{x}^{t_{\max}}_j \beta_{t_{\max}} \>, \sigma^2_{t_{\max}} \Big)$$
$$ \operatorname{logit}(\alpha_j) \sim \mathcal{N}\Big(\mu_{\alpha, j} + \mathbf{x}^{\alpha}_j \beta_{\alpha} \>, \sigma^2_{\alpha} \Big)$$


### The Model 

![](../figures/model2.jpg){height=80%}

### Step 3. Dose Selection

* Goal: Keep patients within some concentration range for as long as possible.
* Not intended to be exhaustive, just demonstrative of capabilities:
  * "One Size Fits All" dose
  * "One Size Fits All" dose + 1 dose adjustment (based on measurement of concentration)
  * Dose based on clinical variables
  * Dose based on clinical variables + 1 dose adjustment
  * Optimal Sampling Time (via Q Learning)
  * Optimal Sequential Dosing (via Q Learning)
* Evaluate the "regret" (difference between maximal time in range and achieved time in range).

### Step 4: Determination of the Return

![](../figures/viz_of_process.png)


### Results

* Modes of personalization which use more information result in lower regret
* Point of diminishing returns
* Would expect Q-learning to perform better when elimination rates were very low, meaning impact of decisions last longer.

![](../figures/models_of_personalization_differences.png)

### Conclusions

* In our case study, covariate adjustment seems to do well enough without additional burden.
* If apixaban were eliminated slower, maybe other forms would have improved.
* Framework can produce evidence for the potential effectiveness and implementation of personalization that respects burden and potentially improves outcomes.
  


## Paper 3: Pooling Pharmacokinetic Information Using Hierarchical Models

### Introduction

* Personalized dosing is a goal of PM.
* Investigators may be able to collect data from some patients, but can be constrained in resources.
* How can investigators use *all* data available for:
  * Discovery
  * Inference
* In this work, pool data from *different* types of studies
* Plus, simulation study to show how sparisty inducing priors can be used for discovery
  
### Background: Discovery

* "Which variables should be in the model?".
* Existing studies us variable selection.  Known deficiencies, including:
  * Bias *away* from the null [@whittingham2006we]
  * Exaggerated precision [@altman1989bootstrap]
  * Uninterpretable p-values [@harrell2015regression]
  * Low confidence to select correctly [@smith2018step].
* Instead,  sparsity inducing priors
* Simulation study to demonstrate sparisty inducing priors on new covariate.

### Background: Inference

* Linear models in some studies
* Known deficiencies:
  * No variation due to other variables (e.g. elimination rate and kidney function)
  * Poor when $t \leq t_{\max}$
  * No integrating over uncertainty
  * Under determination of effects
* Instead, model the pharmacokinetics directly

### Background: Heirarchical Model

* Using data from different studies is an old idea.
* Simply stacking data can violate exchangeability
* Construct an exchangeable model

### Data

![](../figures/table_1_papr_3.jpg)
  

###  The Model

* Exchangeability means one $\sigma_y$ per study.

<center>

![](../figures/model3.jpg){height=80%}

</center>

### Results

![](../figures/simulation-results-1.png)

### Results

![](../figures/plot-model-predictions-1.png)

### Results

![](../figures/effect-estimates-1.png){height=80%}

### Discussion

* Can pool all data, just need to think about DGP
* Many extensions, including between study variability in the effect of variables.
* Posterior consistent with partially pooled models (i.e. regularization)
* Limitations:
  * Effect of NAFLD assumed 0
  * Assumed time delay is 0 for sparsely sampled patients


## Conclusion & Discussion of Thesis

### Discussion

* Compare/contrast existing approaches to fitting Bayesian models
  * HMC leads to better decisions that more popular MAP.
* Framework for "is the juice worth the squeeze".
  * Simulation-based evaluation of personalization based on PK combined with DTRs.
* Demonstrate how PM researchers in academic centers can use all data available to them.
  * Careful considerations of how to pool PK data while maitaining exchangeabiliuty and exploring new variables.
  
  
### Themes

* Need to simulate plausible data and evaluate models on their intended use
* Diminishing returns on persnaliztion and the need to incorporate patient preferences
* Need for efficient use of data resources in study of PM


### Future Work

* Further refinement of PK model to be consistent with expert knowledge
* Learn a better value function through inverse re-inforcement learning
* Multiple imputation methods for pooling data in the case where different variables are recorded in different studies.


### References {.allowframebreaks} 